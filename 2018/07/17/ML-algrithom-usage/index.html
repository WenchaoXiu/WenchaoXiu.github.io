<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="ML, Python, R, Algorithms" />




  


  <link rel="alternate" href="/atom.xml" title="WenchaoXiu" type="application/atom+xml" />






<meta name="description" content="机器学习算法的实践笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习各类算法实践">
<meta property="og:url" content="http://WenchaoXiu.github.io/2018/07/17/ML-algrithom-usage/index.html">
<meta property="og:site_name" content="WenchaoXiu">
<meta property="og:description" content="机器学习算法的实践笔记">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://wenchaoxiu.github.io/2018/07/17/ML-algrithom-usage/images/sklearn.jpg">
<meta property="og:updated_time" content="2018-08-02T03:49:09.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习各类算法实践">
<meta name="twitter:description" content="机器学习算法的实践笔记">
<meta name="twitter:image" content="http://wenchaoxiu.github.io/2018/07/17/ML-algrithom-usage/images/sklearn.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://WenchaoXiu.github.io/2018/07/17/ML-algrithom-usage/"/>





  <title>机器学习各类算法实践 | WenchaoXiu</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">WenchaoXiu</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">just try blog</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://WenchaoXiu.github.io/2018/07/17/ML-algrithom-usage/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="WenchaoXiu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/head.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WenchaoXiu">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器学习各类算法实践</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-17T09:44:48+08:00">
                2018-07-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p class="description">机器学习算法的实践笔记</p>

<p><img src="./images/sklearn.jpg" alt="" style="width:100%"></p>
<a id="more"></a>
<h1 id="笔记简介"><a href="#笔记简介" class="headerlink" title="笔记简介"></a>笔记简介</h1><p>主要整理一下近期学习的机器学习算法具体的实现过程,主要使用的package有scikit-learn,xgboost</p>
<h1 id="sklearn各功能实现"><a href="#sklearn各功能实现" class="headerlink" title="sklearn各功能实现"></a>sklearn各功能实现</h1><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>1.对类别数据进行离散化<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 因为构件数学模型的时候类别特征可以取多个值，不同的值实际上代表的是不同特征属性，因此需要对类别特征进行离散化处理</span></span><br><span class="line"><span class="comment"># 1.利用pandas的get_dummies进行onehot编码</span></span><br><span class="line">newDF = pd.DataFrame()</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> DF.columns:</span><br><span class="line">	tmp = pd.get_dummies(DF[col])</span><br><span class="line">	tmp = pd.rename(columns = <span class="keyword">lambda</span> x: col+<span class="string">'_'</span>+str(x))</span><br><span class="line">	newDF = pd.concat([newDF, tmp], axis=<span class="number">1</span>)</span><br><span class="line">x = newDF.values</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.利用sklearn的label_binarize进行onehot编码</span></span><br><span class="line"><span class="comment"># 除了上述的pd.get_dummies之外的另一种等价方法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> label_binarize</span><br><span class="line">DF_col = label_binarize(DF[col], classes = np.arange(len(pd.unique(DF[col]))))</span><br><span class="line"><span class="comment"># label_binarize返回的和pd.get_dummies返回的对象类似，列数与类别数相同，且只包含01值</span></span><br><span class="line"><span class="comment"># 区别在于，label_binarize返回的是ndarray数据，pd.get_dummies返回的是DataFrame数据</span></span><br><span class="line"><span class="comment"># 因此，np.array_equal(DF_col, pd.get_dummies(DF[col]).values)返回的是True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.sklearn的OneHotEncoder</span></span><br><span class="line"><span class="comment"># 这个功能略感鸡肋(也可能是打开方式不对)给个例子，就不赘述了</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line">x = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],</span><br><span class="line">     [<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>],</span><br><span class="line">     [<span class="number">3</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">     [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],]</span><br><span class="line">ohe = OneHotEncoder(sparse=<span class="keyword">False</span>)</span><br><span class="line"><span class="keyword">print</span> ohe.fit_transform(x)</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]]</span><br></pre></td></tr></table></figure></p>
<p>2.对响应变量进行转换，将类别数据转化为不同int型数字<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">y = DF.accept</span><br><span class="line">y_int = pd.Categorical(y).codes <span class="comment">#得到从0~n-1的n类数字，分别对应不同的类别</span></span><br><span class="line"><span class="comment"># 与上述pd.get_dummies的区别在于，get_dummies返回的是DataFrame数据，且只有01两个值</span></span><br><span class="line"><span class="comment"># 但是上述方法返回的是ndarray数据，返回的值不止01，具体的根据类别数量进行确定</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">y_int = LabelEncoder().fit_transform(y_train)</span><br><span class="line"><span class="comment"># 实现了跟上面相同的功能，输入是不用类别的label，返回的是0~n-1的数字</span></span><br></pre></td></tr></table></figure></p>
<p>3.训练集测试集分割<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这样做的目的是方便测试算法泛化能力</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=<span class="number">0.7</span>)</span><br><span class="line"><span class="comment"># PS:其中x, y是ndarray数据类型，如果是DF数据的话需要使用DF.values进行转化</span></span><br></pre></td></tr></table></figure></p>
<h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><p>1.PCA数据降维<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca_model = PCA(n_components=<span class="number">2</span>, whiten=<span class="keyword">True</span>)</span><br><span class="line">x_pca = pca_model.fit_transform(x)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'top2 方差'</span>, pca_model.explained_variance_</span><br><span class="line"><span class="keyword">print</span> <span class="string">'top2 方差所占比例'</span>, pca_model.explained_variance_ratio_</span><br><span class="line"><span class="comment"># 其中的n_component是选择将数据降维后，选取其中的n个特征（特征顺序按照特征值从高到低排序）</span></span><br><span class="line"><span class="comment"># pca_model.explained_variance_是对应的前两个特征的方差</span></span><br><span class="line"><span class="comment"># pca_model.explained_variance_ratio_是前两个特征的方差占总方差的比例</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.lmplot(x = <span class="string">'pc1'</span>, y=<span class="string">'pc2'</span>, data = pc_plot_data, hue=type, fit_reg=<span class="keyword">False</span>)</span><br><span class="line">ax = plt.gca()</span><br><span class="line">ax.set_title(<span class="string">"Iris PCA 2 compotent"</span>, fontsize=<span class="number">20</span>)</span><br><span class="line"><span class="comment"># 上述代码用来绘图</span></span><br></pre></td></tr></table></figure></p>
<p><a href="https://www.cnblogs.com/pinard/p/6243025.html" target="_blank" rel="noopener">使用教程</a></p>
<p>2.特征筛选<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 利用sklearn的SelectKBest进行特征选择</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest, chi2</span><br><span class="line">chi2_model = SelectKBest(chi2, k=<span class="number">2</span>)</span><br><span class="line">chi2_model.fit(x, y)</span><br><span class="line">selected_col = chi2_model.get_support(indices=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># 之所以x和y都需要加进去是因为需要对每个特征和响应变量进行chi2检验，按照显著性排序，找到前两个特征（原特征）</span></span><br><span class="line"><span class="comment"># indices是为了返回对应的column数</span></span><br></pre></td></tr></table></figure></p>
<p><a href="http://sklearn.apachecn.org/cn/0.19.0/modules/feature_selection.html" target="_blank" rel="noopener">官方文档</a> &amp; <a href="http://bluewhale.cc/2016-11-25/use-scikit-learn-for-feature-selection.html" target="_blank" rel="noopener">使用教程</a> &amp; <a href="http://d0evi1.com/sklearn/feature_selection/" target="_blank" rel="noopener">特征提取</a></p>
<p>3.原始特征变化<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line">poly = PolynomialFeatures(degree = <span class="number">2</span>, include_bias=<span class="keyword">True</span>, interaction_only=<span class="keyword">False</span>)</span><br><span class="line">x_poly = poly.fit_transform(x)</span><br><span class="line"><span class="comment"># 对数据特征进行变换，degree是特征的最高维数，include_bias加不加一列1，interaction_only是否只看有交互的特征</span></span><br></pre></td></tr></table></figure></p>
<h2 id="构建有监督模型"><a href="#构建有监督模型" class="headerlink" title="构建有监督模型"></a>构建有监督模型</h2><p>1.逻辑回归模型用于分类（Logistic Regression）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklean.linear_model <span class="keyword">import</span> LogisticRegressionCV, Lasso</span><br><span class="line">model = LinearRegeressionCV(Cs = np.logspace(<span class="number">-3</span>,<span class="number">4</span>,<span class="number">8</span>), cv = <span class="number">5</span>, n_job = <span class="number">-1</span>)</span><br><span class="line">model.fit(x_train, y_train)</span><br><span class="line">y_train_hat = model.predict(x_train) <span class="comment"># 对训练集进行预测</span></span><br><span class="line">y_test_hat = model.predict(x_test) <span class="comment"># 对测试集进行预测</span></span><br><span class="line"><span class="keyword">print</span> model.C_ <span class="comment"># 获得各类别最佳超参数</span></span><br><span class="line"><span class="comment"># LinearRegeressionCV是一种自动确定正则化超参数的函数，其中Cs是一系列的正则化参数值，一般需要取不同数量级的数字</span></span><br><span class="line"><span class="comment"># cv是进行cross validation对超参数最优解进行确定，n_job=-1是用上全部线程，这里默认的正则是L2 norm</span></span><br><span class="line"><span class="comment"># PS:注意在进行多分类的时候选择的方法是one vers rest也就是一对多进行多分类</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意除了自带的cross-validation方法，还可以用更加普遍的方法GridSearchCV</span></span><br><span class="line">model = Lasso()</span><br><span class="line">GS_Lasso = GridSearchCV(model, param_grid=&#123;<span class="string">'alpha'</span>:np.logspace(<span class="number">-3</span>,<span class="number">4</span>,<span class="number">8</span>)&#125;, cv=<span class="number">5</span>)</span><br><span class="line">GS_Lasso.fit(x_train, y_train)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'Lasso model最优参数: '</span>, GS_Lasso.best_params_</span><br></pre></td></tr></table></figure></p>
<p>2.决策树模型（DesitionTree）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对决策树的不同深度进行探究，求取对应的准确率</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">model = DecisionTreeClassifier()</span><br><span class="line">acc = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">15</span>):</span><br><span class="line">    model.set_params(max_depth=i)</span><br><span class="line">    model.fit(x_train, y_train)</span><br><span class="line">    y_test_hat = model.predict(x_test)</span><br><span class="line">    acc.append(metrics.accuracy_score(y_test, y_test_hat))</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>,<span class="number">15</span>), acc, <span class="string">'ro'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'accuracy'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'depth'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#决策树进行回归</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line">reg = DecisionTreeRegressor(criterion=<span class="string">'mse'</span>, max_depth=deep)</span><br><span class="line">dt = reg.fit(x, y)</span><br></pre></td></tr></table></figure></p>
<p>3.随机森林模型（RandomForest）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line">RF_model = RandomForestRegressor()</span><br><span class="line">RF_model.fit(x_train, y_train)</span><br><span class="line">y_train_hat = RF_model.predict(y_train)</span><br><span class="line"><span class="comment"># 对于多值输出问题来说一般采用多值输出的方法进行模型构建，主要从两个角度：a.每个叶节点存储多个值 b.通过计算多个值的平均减少量作为split标准</span></span><br></pre></td></tr></table></figure></p>
<p><a href="http://sklearn.apachecn.org/cn/latest/modules/tree.html" target="_blank" rel="noopener">参考</a> &amp; <a href="https://www.cnblogs.com/pinard/p/6160412.html" target="_blank" rel="noopener">随机森林调参</a></p>
<p>4.bagging模型<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> BaggingRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line">DT_model = DecisionTreeRegressor(max_depth=<span class="number">9</span>)</span><br><span class="line">ridge_BG_model = BaggingRegressor(Pipeline([(<span class="string">'poly'</span>, PolynomialFeatures(degree=<span class="number">6</span>)), </span><br><span class="line">                                            (<span class="string">'ridge'</span>, linear_model.RidgeCV(alphas=np.logspace(<span class="number">-3</span>,<span class="number">4</span>,<span class="number">8</span>), cv=<span class="number">5</span>, fit_intercept=<span class="keyword">False</span>))])</span><br><span class="line">                                  , n_estimators=n_estimators, max_samples=max_samples)</span><br><span class="line">DT_BG_model = BaggingRegressor(DT_model, n_estimators=n_estimators, max_samples=max_samples)</span><br><span class="line"><span class="comment"># bagging是一种构建多个基分类器，对数据进行预测，并平均多个分类器的预测值的一种方法</span></span><br><span class="line"><span class="comment"># 输入需要有基分类器，基分类器的个数，以及对于样本选取的比例</span></span><br></pre></td></tr></table></figure></p>
<p>5.Adaboost模型<br><a href="http://www.cnblogs.com/pinard/p/6133937.html" target="_blank" rel="noopener">原理</a> &amp; <a href="https://www.cnblogs.com/pinard/p/6136914.html" target="_blank" rel="noopener">模型参数</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">base = DecisionTreeClassifier(n_estimators=<span class="number">100</span>, max_depth = <span class="number">3</span>, min_sample_split=<span class="number">4</span>, random_state=<span class="number">1</span>, oob_score=<span class="keyword">True</span>) </span><br><span class="line"><span class="comment"># 超过4个样本就进行样本的分割构建叶节点, 基分类器个数100，最大树深3，oob_score考虑带外分数</span></span><br><span class="line">AB_model = AdaBoostClassifier(base_estimator = base, learning_rate = <span class="number">0.1</span>)</span><br><span class="line">AB_model.fit(x_train, y_train)</span><br><span class="line">y_train_hat = AB_model.predict(x_train)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'训练集准确度: %.5.f'</span>%metrics.accuracy_score(y_train, y_train_hat)</span><br><span class="line"><span class="comment"># Adaboost是另一种集成模型，利用决策树模型作为基分类器，与上面的bagging的区别在于，bagging是可以并行的，各个模型的确定可以随机产生，最后平均化即可</span></span><br><span class="line"><span class="comment"># 但是对于Adaboost来说各个基分类器是串行产生的，每次新产生的分类器都与前面所有的分类器相关，具体是新的分类器是通过前面所有模型的残差和确定的</span></span><br><span class="line"><span class="comment"># 相当于不断强化基分类器与真实值的差别，因此Adaboost的基分类器需要更加泛化相比较Bagging的及模型</span></span><br><span class="line"><span class="comment"># 举个例子假如基分类器都是决策树，Bagging的深度更深，Adaboost的深度更浅</span></span><br><span class="line"><span class="comment"># 这里learning_rate实际上是fk(x)=fk−1(x)+ναkGk(x)中的ν(0&lt;ν&lt;1)，其中αk是根据分类器的错误率进行确定的模型权重</span></span><br><span class="line"><span class="comment"># Gk(x)是根据样本权重重新确定的基分类器，fk(x)是膜前获得的强分类器是k个基分类器的结合，理论上ν越小的话迭代下次数越多</span></span><br></pre></td></tr></table></figure></p>
<p>6.GBDT模型<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#GBDT 每个基分类器要相对弱一点因为是提升树</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line">gbdt_model = GradientBoostingClassifier(learning_rate=<span class="number">0.1</span>, max_depth=<span class="number">3</span>, n_estimators=<span class="number">100</span>)</span><br><span class="line">gbdt_model.fit(x_train, y_train)</span><br><span class="line">gbdt_y_train_hat = gbdt_model.predict(x_train)</span><br><span class="line">gbdt_y_test_hat = gbdt_model.predict(x_test)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'训练集准确率: %.4f'</span>%metrics.accuracy_score(y_train, gbdt_y_train_hat)</span><br></pre></td></tr></table></figure></p>
<p>7.xgboost模型<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xgboost也是一种快速效果好的集成模型</span></span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line">train_data = xgb.DMatrix(x_train, y_train)</span><br><span class="line">test_data = xgb.DMatrix(x_test, y_test)</span><br><span class="line">watch_list = [(test_data, <span class="string">'eval'</span>), (train_data, <span class="string">'train'</span>)]</span><br><span class="line">params = &#123;<span class="string">'eta'</span>:<span class="number">0.1</span>, <span class="string">'max_depth'</span>:<span class="number">6</span>, <span class="string">'objective'</span>:<span class="string">'multi:softmax'</span>, <span class="string">'num_class'</span>:<span class="number">3</span>&#125;</span><br><span class="line">xgb_model = xgb.train(params, train_data, num_boost_round=<span class="number">50</span>, evals=watch_list, evals_result=&#123;<span class="string">'eval_metric'</span>:<span class="string">'logloss'</span>&#125;) <span class="comment">#设置对应评估指标</span></span><br><span class="line">y_test_hat_xgb = xgb_model.predict(test_data) <span class="comment">#######test_data类型，xgb_model跟sklearn不同</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'xgb model: %.3f'</span>%(sum(y_test_hat_xgb==y_test)*<span class="number">1.0</span>/len(y_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用XGBOOST的sklearn接口进行模型构建，这个方便点使用习惯和sklearn其他模型类似</span></span><br><span class="line">xgb_model = xgb.XGBClassifier(learning_rate=<span class="number">0.1</span>, n_estimators=<span class="number">100</span>, max_depth=<span class="number">2</span>, objective=<span class="string">'multi:softmax'</span>)</span><br><span class="line">xgb_model.fit(x_train, y_train)</span><br><span class="line">xgb_y_train_hat = xgb_model.predict(x_train)</span><br><span class="line">xgb_y_test_hat = xgb_model.predict(x_test)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'训练集准确率: %.4f'</span>%metrics.accuracy_score(y_train, xgb_y_train_hat)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'验证集准确率: %.4f'</span>%metrics.accuracy_score(y_test, xgb_y_test_hat)</span><br></pre></td></tr></table></figure></p>
<p><a href="https://xgboost.readthedocs.io/en/latest/python/python_api.html?highlight=fit#module-xgboost.sklearn" target="_blank" rel="noopener">sklearn API</a> &amp; <a href="https://blog.csdn.net/sb19931201/article/details/52557382" target="_blank" rel="noopener">参数解释</a> &amp; <a href="https://github.com/dmlc/xgboost/tree/master/demo#tutorials" target="_blank" rel="noopener">github使用教程</a> &amp; <a href="https://www.zhihu.com/question/41354392/answer/98658997" target="_blank" rel="noopener">GDBT和XGBOOSt区别</a> &amp; <a href="https://zhuanlan.zhihu.com/p/28663369" target="_blank" rel="noopener">Tatanic实例</a> &amp; <a href="https://zhuanlan.zhihu.com/p/31182879" target="_blank" rel="noopener"><strong>知乎教程</strong></a> &amp; <a href="https://zhuanlan.zhihu.com/p/26683576" target="_blank" rel="noopener"><strong>Ensemble模型介绍</strong></a></p>
<p>8.SVM模型<a href="https://www.cnblogs.com/pinard/p/6117515.html" target="_blank" rel="noopener">参考</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line">model = svm.SVC(C=<span class="number">0.1</span>, kernel=<span class="string">'linear'</span>, decision_function_shape=<span class="string">'ovr'</span>, class_weight=&#123;<span class="number">-1</span>:<span class="number">1</span>, <span class="number">1</span>:weight[<span class="number">0</span>]&#125;)</span><br><span class="line">model.fit(x_train, y_train)</span><br><span class="line">y_train_hat = model.predit(x_train)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'decision_function:\n'</span>, clf.decision_function(x_train)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'\npredict:\n'</span>, clf.predict(x_train)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'支撑向量的数目：'</span>, clf.n_support_</span><br><span class="line"><span class="keyword">print</span> <span class="string">'支撑向量的系数：'</span>, clf.dual_coef_</span><br><span class="line"><span class="keyword">print</span> <span class="string">'支撑向量: '</span>, clf.support_ <span class="comment"># 这个是对应的支持向量的索引值</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'模型精度: '</span>, model.score(x_train, y_train)</span><br><span class="line"><span class="comment"># C是惩罚系数，当C很大的时候为了保证损失函数最小对应的惩罚因子需要很小，使得模型很严格，决策边界之间的距离很小</span></span><br><span class="line"><span class="comment"># class_weight是为了方便对不平衡数据的操作，如果类别数据数量级差的太多的话会使模型准确度下降</span></span><br><span class="line"><span class="comment"># kernel可以选择不同的核函数，decision_function_shape是进行one vers rest，可以使用ovo,这样的话一对一</span></span><br><span class="line"><span class="comment"># decision_function计算每个样本到每一类的距离，选取最大的那个作为预测类别（因为在决策边界两侧），decision_function的ovr和ovo列数有差别</span></span><br><span class="line"><span class="comment"># predict就是正常的返回类别对应的数字</span></span><br><span class="line"><span class="comment"># svm的score返回的是精度类似于metrics.accuracy_score(x_train, y_train)</span></span><br><span class="line"></span><br><span class="line">weight = [<span class="number">2</span>,<span class="number">30</span>,<span class="number">2</span>,<span class="number">30</span>]</span><br><span class="line">clfs = [svm.SVC(C=<span class="number">1</span>, kernel=<span class="string">'linear'</span>, class_weight=&#123;<span class="number">-1</span>:<span class="number">1</span>, <span class="number">1</span>:weight[<span class="number">0</span>]&#125;),</span><br><span class="line">       svm.SVC(C=<span class="number">1</span>, kernel=<span class="string">'linear'</span>, class_weight=&#123;<span class="number">-1</span>:<span class="number">1</span>, <span class="number">1</span>:weight[<span class="number">1</span>]&#125;),</span><br><span class="line">       svm.SVC(C=<span class="number">0.8</span>, kernel=<span class="string">'rbf'</span>, gamma=<span class="number">0.5</span>, class_weight=&#123;<span class="number">-1</span>:<span class="number">1</span>, <span class="number">1</span>:weight[<span class="number">2</span>]&#125;),</span><br><span class="line">       svm.SVC(C=<span class="number">0.8</span>, kernel=<span class="string">'rbf'</span>, gamma=<span class="number">0.5</span>, class_weight=&#123;<span class="number">-1</span>:<span class="number">1</span>, <span class="number">1</span>:weight[<span class="number">3</span>]&#125;)]</span><br><span class="line"><span class="comment"># 对于不平衡数据进行权重的分配，保证结果的准确性</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用SVM进行回归分析</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line">print(<span class="string">'SVR - RBF'</span>)</span><br><span class="line">svr_rbf = svm.SVR(kernel=<span class="string">'rbf'</span>, gamma=<span class="number">0.2</span>, C=<span class="number">100</span>)</span><br><span class="line">svr_rbf.fit(x, y)</span><br><span class="line">print(<span class="string">'SVR - Linear'</span>)</span><br><span class="line">svr_linear = svm.SVR(kernel=<span class="string">'linear'</span>, C=<span class="number">100</span>)</span><br><span class="line">svr_linear.fit(x, y)</span><br><span class="line">print(<span class="string">'SVR - Polynomial'</span>)</span><br><span class="line">svr_poly = svm.SVR(kernel=<span class="string">'poly'</span>, degree=<span class="number">3</span>, C=<span class="number">100</span>)</span><br><span class="line">svr_poly.fit(x, y)</span><br><span class="line">print(<span class="string">'Fit OK.'</span>)</span><br><span class="line"><span class="comment"># 注意这里kernel可以选择linear/rbf分别对应线性核以及高斯核，其中线性核和高斯核分别有两个比较重要的参数</span></span><br><span class="line"><span class="comment"># C和gamma，其中C上面已经解释过了，gamma是一个跟核函数相关的参数，gamma是∂2的倒数，表征高斯核的方差大小，</span></span><br><span class="line"><span class="comment"># 所以∂2的倒数表征的是高斯核的精度，gamma值越大也就数据在训练集上准确度越高，增大过拟合的风险</span></span><br><span class="line"><span class="comment"># PS:kernel还可以选择poly多项式核，配合的参数是degree</span></span><br></pre></td></tr></table></figure></p>
<h2 id="构建无监督模型"><a href="#构建无监督模型" class="headerlink" title="构建无监督模型"></a>构建无监督模型</h2><p>1.Kmeans聚类<a href="https://www.cnblogs.com/pinard/p/6169370.html" target="_blank" rel="noopener">参考</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets <span class="keyword">as</span> ds</span><br><span class="line">x, y = ds.make_blobs(<span class="number">400</span>, n_features=<span class="number">2</span>, centers=<span class="number">4</span>, cluster_std=(<span class="number">1</span>, <span class="number">2.5</span>, <span class="number">0.5</span>, <span class="number">2</span>), random_state=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 这个函数的功能是根据高斯分布进行构建随机数据，用于后续的聚类分析</span></span><br><span class="line"><span class="comment"># 其中400是产生的样本的个数，n_features是产生的数据的维度，centers是对应数据的类别，cluster_std是定义不同类别的方差</span></span><br><span class="line"><span class="comment"># 这里centers可以是一组array数据，作为中心</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">model = KMeans(n_clusters=<span class="number">4</span>, init=<span class="string">'k-means++'</span>, n_init=<span class="number">10</span>, max_iter=<span class="number">300</span>)</span><br><span class="line">model.fit(x, y)</span><br><span class="line">y_hat = model.predict(x)</span><br><span class="line">model.cluster_centers_ <span class="comment"># 输出对应的聚类中心</span></span><br><span class="line"><span class="comment"># KMeans算法主要有这几个主要参数，n_cluster是聚类类别，init是中心点初始化方法，因为KMeans初值敏感所以需要迭代多次，</span></span><br><span class="line"><span class="comment"># n_init就是控制这个的参数，当数据是非凸集的时候max_iter的设置防止算法不收敛</span></span><br></pre></td></tr></table></figure></p>
<p>2.AP聚类算法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> AffinityPropagation</span><br><span class="line">model = AffinityPropagation(affinity=<span class="string">'euclidean'</span>)</span><br><span class="line">model.fit(x, y)</span><br><span class="line">model.cluster_centers_indices_ <span class="comment"># 返回的是中心点的索引</span></span><br><span class="line">y_hat = model.labels_ <span class="comment">#返回的是预测的数据类别</span></span><br></pre></td></tr></table></figure></p>
<p>3.DBSCAN算法(<a href="https://www.cnblogs.com/pinard/p/6208966.html" target="_blank" rel="noopener">参考1</a>,<a href="http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html#sphx-glr-auto-examples-cluster-plot-dbscan-py" target="_blank" rel="noopener">参考2</a>)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line">model = DBSCAN(eps=m, min_samples=n) <span class="comment"># eps对应算法的半径, min_samples对应算法在ε半径之内包含的最小点数，用来确定核心对象</span></span><br><span class="line">model.fit(x)</span><br><span class="line">y_hat = model.labels_ <span class="comment"># 预测类别值</span></span><br><span class="line">y_coresample = model.core_sample_indices_ <span class="comment"># 预测类别中心点</span></span><br><span class="line">n_clusters_ = len(set(y_hat)) - (<span class="number">1</span> <span class="keyword">if</span> <span class="number">-1</span> <span class="keyword">in</span> y_hat <span class="keyword">else</span> <span class="number">0</span>) <span class="comment"># 注意算法会把噪音点归为-1</span></span><br><span class="line"><span class="comment"># DBSCAN对数据本身没有分布要求，不像Kmeans假设数据是高斯分布的，DBSCAN产生的聚类形状可以不为类圆形</span></span><br><span class="line"><span class="comment"># 固定ε，min_samples越大越严格；固定min_samples，ε越小越严格</span></span><br><span class="line"><span class="comment"># DBSCAN通过计算每个数据点的高局部密度点距离和本身的密度确定每个点的类别，高局部密度点距离大密度大的点为聚类中心</span></span><br><span class="line"><span class="comment"># 高局部密度点距离大密度小的点为噪声，高局部密度点距离小密度大的点为普通点，高局部密度点距离小密度大的点不好判断</span></span><br><span class="line"><span class="comment"># ps:密度就是每个点ε邻域内的点数，高局部密度点距离就是比该点密度大的点中与之距离最小的距离</span></span><br></pre></td></tr></table></figure></p>
<p>4.MeanShift聚类<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> MeanShift</span><br><span class="line">model = MeanShift(bin_seeding=<span class="keyword">True</span>, bandwidth=band_width)</span><br><span class="line"><span class="comment"># 只需要给出圆的半径就好，圆的中心根据圆圈内包含的点的中心不断更新</span></span><br></pre></td></tr></table></figure></p>
<h2 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h2><p>1.模型准确率<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">print</span> <span class="string">'训练集准确率: %.5f'</span>%metrics.accuracy_score(y_train, y_train_hat) <span class="comment"># 先放真实值再放预测值，类型是ndarray</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'测试集准确率: %.5f'</span>%metrics.accuracy_score(y_test, y_test_hat) <span class="comment"># 先放真实值再放预测值，类型是ndarray</span></span><br><span class="line"><span class="comment"># 这里y_train和y_train_hat都是由0、1组成的</span></span><br></pre></td></tr></table></figure></p>
<p>2.模型的ROC、AUC<a href="https://blog.csdn.net/YE1215172385/article/details/79443552" target="_blank" rel="noopener">micro/macro</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">micro_AUC = metrics.roc_auc_score(y_true, y_probability, average=<span class="string">'micro'</span>)</span><br><span class="line">macro_AUC = metrics.roc_auc_score(y_true, y_probability, average=<span class="string">'macro'</span>)</span><br><span class="line">fpr, tpr, threshold = metrics.roc_curve(y_true.ravel(), y_probability.ravel())</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>), dpi=<span class="number">80</span>, facecolor=<span class="string">'w'</span>)</span><br><span class="line">plt(fpr, tpr, <span class="string">'r-'</span>, lw=<span class="number">2</span>, label=<span class="string">'AUC: %.5f'</span>%micro_AUC)</span><br><span class="line">plt.xlabel(<span class="string">'FPR'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'TPR'</span>)</span><br><span class="line">plt.xticks(np.arange(<span class="number">-0.1</span>, <span class="number">1.1</span>, <span class="number">0.1</span>))</span><br><span class="line">plt.yticks(np.arange(<span class="number">-0.1</span>, <span class="number">1.1</span>, <span class="number">0.1</span>))</span><br><span class="line">plt.title(<span class="string">'ROC curve'</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.grid(b=<span class="keyword">True</span>, ls=<span class="string">':'</span>)</span><br><span class="line">plt.legend(loc = <span class="string">'lower right'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对上述评估标准进行说明，首先y_true和y_probability是一个n*m的ndarray对象，n是样本数，m是响应变量的类别数</span></span><br><span class="line"><span class="comment"># 其中y_true是对应多类别的真实值，每一行只有一个1其余为0，y_probability每一行是不同类别的预测概率</span></span><br><span class="line"><span class="comment"># 在计算AUC得分的时候，如果是多分类问题，有两种计算方式，第一种对每一列绘制ROC计算AUC，即对每一类别分别计算</span></span><br><span class="line"><span class="comment"># 另一种是将n*m的矩阵按行首尾连接，形成一个n*m长的array，对其绘制ROC同时计算AUC，这两种分别是macro和micro</span></span><br><span class="line"><span class="comment"># metrics.roc_curve是用来获得在不同theshold下得到的FPR和TPR的对应值，其中.ravel()方法用来展开数据，相当于按照micro的方法绘制</span></span><br></pre></td></tr></table></figure></p>
<p>3.模型的MSE(Mean square error)<a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=10814010" target="_blank" rel="noopener">参考</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算模型的均方误差</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">metrics.mean_squared_error(y_True, y_hat)</span><br></pre></td></tr></table></figure></p>
<p>4.模型的其他评估(Mean square error) <a href="https://blog.argcv.com/articles/1036.c" target="_blank" rel="noopener">参考</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score, recall_score, f1_score, fbeta_score</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_fscore_support, classification_report</span><br><span class="line">fbeta = fbeta_score(y_true, y_hat, beta=beta)</span><br><span class="line">precision = precision_score(y_true, y_hat)</span><br><span class="line">recall = recall_score(y_true, y_hat)</span><br><span class="line">print(<span class="string">'f1 score: \t'</span>, f1_score(y_true, y_hat))</span><br><span class="line">fbeta = fbeta_score(y_true, y_hat, beta=beta)</span><br><span class="line"><span class="comment"># precision score = tp/(tp+fp)和准确度的区别在于只关注正类，准确率是所有类别都关注</span></span><br><span class="line"><span class="comment"># recal score = tp/(tp+fn)</span></span><br><span class="line"><span class="comment"># F1 = 2*(precision*recall)/(precision+recall) F1相当于P和R调和均值，越大模型效果越好</span></span><br><span class="line"><span class="comment"># fbeta_score是P和R的调和均值，beta&lt;1 precision的权重更大，beta&gt;1 recall的权重更大</span></span><br></pre></td></tr></table></figure></p>
<p>5.聚类方法的评估(<a href="https://blog.csdn.net/Mr_tyting/article/details/76719062" target="_blank" rel="noopener">方法解释</a><a href="https://blog.csdn.net/sinat_26917383/article/details/70577710" target="_blank" rel="noopener">参考1</a>, <a href="http://sklearn.apachecn.org/cn/0.19.0/modules/clustering.html" target="_blank" rel="noopener">参考2</a>)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Homogeneity：'</span>, homogeneity_score(y, y_pred))</span><br><span class="line">print(<span class="string">'completeness：'</span>, completeness_score(y, y_pred))</span><br><span class="line">print(<span class="string">'V measure：'</span>, v_measure_score(y, y_pred))</span><br><span class="line">print(<span class="string">'AMI：'</span>, adjusted_mutual_info_score(y, y_pred))</span><br><span class="line">print(<span class="string">'ARI：'</span>, adjusted_rand_score(y, y_pred))</span><br><span class="line">print(<span class="string">'Silhouette：'</span>, silhouette_score(x, y_pred), <span class="string">'\n'</span>) <span class="comment"># 轮廓系数，1-类内距离/最小类外距离，1的时候最优，真实值也不一定是1..</span></span><br><span class="line"><span class="comment"># 聚类算法在真实的应用中一般难以获取真实的数据标签，除非手动区分，所以上述评估标准比较鸡肋，不深入解释</span></span><br></pre></td></tr></table></figure></p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>1.欧氏距离计算<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> euclidean_distances</span><br><span class="line">m = euclidean_distances(data, squared=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># 返回一个n*n的矩阵计算的是亮亮之间的距离</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Pipeline构建"><a href="#Pipeline构建" class="headerlink" title="Pipeline构建"></a>Pipeline构建</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pipeline的使用是为了方便对数据处理的流程化，举个简单的example:特征变换+逻辑回归</span></span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegressionCV</span><br><span class="line">model = Pipeline([</span><br><span class="line">	(<span class="string">'poly'</span>, PolynomialFeatures(degree = <span class="number">2</span>, include_bias = <span class="keyword">True</span>)),</span><br><span class="line">	(<span class="string">'LR'</span>, LogisticRegressionCV(Cs = np.logspace(<span class="number">-3</span>, <span class="number">4</span>, <span class="number">8</span>), cv = <span class="number">5</span>, fit_intercept = <span class="keyword">False</span>))</span><br><span class="line">])</span><br><span class="line">model.fit(x_train, y_train)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'最优参数:  '</span>, model.get_params(<span class="string">'LR'</span>)[<span class="string">'LR'</span>].C_</span><br><span class="line"><span class="comment"># model包括两步，第一步对特征进行转换，第二步对转换好的特征进行逻辑回归模型构建</span></span><br></pre></td></tr></table></figure>
<p><a href="https://blog.csdn.net/lanchunhui/article/details/50521648" target="_blank" rel="noopener">Pipeline原理解析</a></p>
<h2 id="参数验证"><a href="#参数验证" class="headerlink" title="参数验证"></a>参数验证</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> best_estimator_, RandomizedSearchCV    <span class="comment"># 0.17 grid_search</span></span><br><span class="line">model = svm.SVR(kernel=<span class="string">'rbf'</span>)</span><br><span class="line">c_can = np.logspace(<span class="number">-2</span>, <span class="number">2</span>, <span class="number">10</span>)</span><br><span class="line">gamma_can = np.logspace(<span class="number">-2</span>, <span class="number">2</span>, <span class="number">10</span>)</span><br><span class="line">svr = GridSearchCV(model, param_grid=&#123;<span class="string">'C'</span>: c_can, <span class="string">'gamma'</span>: gamma_can&#125;, cv=<span class="number">5</span>)</span><br><span class="line">svr.fit(x, y)</span><br><span class="line">print(<span class="string">'验证参数：\n'</span>, svr.best_params_)</span><br><span class="line"><span class="comment"># cross validation交叉验证对应的参数</span></span><br><span class="line"><span class="comment"># best_params_对应model的参数，对于内部的参数通过best_params_之后再提取，比如svr中的support_</span></span><br></pre></td></tr></table></figure>
<h2 id="分类数据进行绘图"><a href="#分类数据进行绘图" class="headerlink" title="分类数据进行绘图"></a>分类数据进行绘图</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.对于多分类数据进行划分区域，对坐标轴中的各个点进行预测，并对预测的点给与相应的颜色，例如对x1，x2进行绘图</span></span><br><span class="line">x1_min, x1_max = x1.min(), x1.max()</span><br><span class="line">x2_min, x2_max = x2.min(), x2.max()</span><br><span class="line">x1_array = np.arange(x1_min, x1_max, <span class="number">0.02</span>)</span><br><span class="line">x2_array = np.arange(x2_min, x2_max, <span class="number">0.02</span>)</span><br><span class="line">x1_tmp, x2_tmp = np.meshgrid(x1_array, x2_array)</span><br><span class="line">x_plot = np.stack((x1_tmp.flat, x2_tmp.flat), axis=<span class="number">1</span>) <span class="comment">#x_plot是一个列为2的数据，第一列是x轴值，第二列是y轴值</span></span><br><span class="line">y_meshgrid_hat = model.predict(x_plot)</span><br><span class="line">plt.scatter(x_plot[:,<span class="number">0</span>], x_plot[:,<span class="number">1</span>], c=y_meshgrid_hat, cmap = mpl.colors.ListedColormap([<span class="string">'#77E0A0'</span>, <span class="string">'#FF8080'</span>, <span class="string">'#A0A0FF'</span>]))</span><br><span class="line">plt.scatter(data.iloc[:,<span class="number">2</span>].values, data.iloc[:,<span class="number">3</span>].values, c=pd.Categorical(data.iloc[:,<span class="number">-1</span>]).codes, cmap = mpl.colors.ListedColormap([<span class="string">'g'</span>, <span class="string">'r'</span>, <span class="string">'b'</span>]))</span><br><span class="line"><span class="comment"># cmap参数是对应到不同的y_meshgrid_hat的值的颜色</span></span><br><span class="line">参考: http://sklearn.apachecn.org/cn/<span class="number">0.19</span><span class="number">.0</span>/auto_examples/linear_model/plot_iris_logistic.html<span class="comment">#sphx-glr-auto-examples-linear-model-plot-iris-logistic-py</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 类似的绘图方法</span></span><br><span class="line">x1, x2 = np.mgrid[x1_min:x1_max:<span class="number">500j</span>, x2_min:x2_max:<span class="number">500j</span>]</span><br><span class="line">cm_light = mpl.colors.ListedColormap([<span class="string">'#FF8080'</span>, <span class="string">'#80FF80'</span>, <span class="string">'#8080FF'</span>, <span class="string">'#F0F080'</span>])</span><br><span class="line">cm_dark = mpl.colors.ListedColormap([<span class="string">'r'</span>, <span class="string">'g'</span>, <span class="string">'b'</span>, <span class="string">'y'</span>])</span><br><span class="line">mpl.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]</span><br><span class="line">mpl.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="keyword">False</span></span><br><span class="line">plt.figure(facecolor=<span class="string">'w'</span>)</span><br><span class="line">plt.pcolormesh(x1, x2, y_test, cmap=cm_light)</span><br><span class="line">plt.contour(x1, x2, y_test, levels=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>), colors=<span class="string">'k'</span>, linestyles=<span class="string">'--'</span>)</span><br><span class="line">plt.scatter(x[:, <span class="number">0</span>], x[:, <span class="number">1</span>], s=<span class="number">20</span>, c=y, cmap=cm_dark, edgecolors=<span class="string">'k'</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">plt.xlabel(<span class="string">'$X_1$'</span>, fontsize=<span class="number">11</span>)</span><br><span class="line">plt.ylabel(<span class="string">'$X_2$'</span>, fontsize=<span class="number">11</span>)</span><br><span class="line">plt.xlim((x1_min, x1_max))</span><br><span class="line">plt.ylim((x2_min, x2_max))</span><br><span class="line">plt.grid(b=<span class="keyword">True</span>)</span><br><span class="line">plt.tight_layout(pad=<span class="number">2.5</span>)</span><br><span class="line">plt.title(<span class="string">'SVM多分类方法：One/One or One/Other'</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.单独做legend，不推荐，需要自己去看对应的类别，如果需要绘图上的调整还是用python吧</span></span><br><span class="line">patchs = [mpatches.Patch(color=<span class="string">'red'</span>, label=<span class="string">'Iris-setosa'</span>),</span><br><span class="line">          mpatches.Patch(color=<span class="string">'green'</span>, label=<span class="string">'Iris-versicolor'</span>),</span><br><span class="line">          mpatches.Patch(color=<span class="string">'blue'</span>, label=<span class="string">'Iris-virginica'</span>)]</span><br><span class="line">plt.legend(handles=patchs, fancybox=<span class="keyword">True</span>, framealpha=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.对预测值和真实值进行对比</span></span><br><span class="line">y_order = y_test.argsort()</span><br><span class="line">plt.plot(np.arange(len(y_order)), y_test[y_order], <span class="string">'g-'</span>, label=<span class="string">'True'</span>)</span><br><span class="line">plt.plot(np.arange(len(y_order)), y_test_hat[y_order], <span class="string">'r-'</span>, label=<span class="string">'Predicted'</span>)</span><br><span class="line"><span class="comment"># 分别绘制真实值和预测值，看两者的差别</span></span><br></pre></td></tr></table></figure>
<h2 id="模型保存"><a href="#模型保存" class="headerlink" title="模型保存"></a>模型保存</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">if</span> os.path.exists(<span class="string">'xxx.model'</span>):</span><br><span class="line">	model = joblib.load(<span class="string">'xxx.model'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">	joblib.dump(model, <span class="string">'xxx.model'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="tips"><a href="#tips" class="headerlink" title="tips"></a>tips</h2><ol>
<li><p>对于使用sklearn过程中出现warning的情况，可以通过使用下列代码进行warning的隐藏</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>对于使用jupyter notbook的同学可以使用magic命令使得画图的时候直接显示图片代替 “matplotlib.pyplot.show()”</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">% matplotlib inline</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="还有一些东西没来得及总计，有机会再补充"><a href="#还有一些东西没来得及总计，有机会再补充" class="headerlink" title="还有一些东西没来得及总计，有机会再补充"></a>还有一些东西没来得及总计，有机会再补充</h2><p>#####################   2018.8.2   ############################</p>
<hr>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/07/12/pandas-commands/" rel="next" title="pandas 常用命令笔记">
                <i class="fa fa-chevron-left"></i> pandas 常用命令笔记
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/head.jpeg"
                alt="WenchaoXiu" />
            
              <p class="site-author-name" itemprop="name">WenchaoXiu</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#笔记简介"><span class="nav-number">1.</span> <span class="nav-text">笔记简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#sklearn各功能实现"><span class="nav-number">2.</span> <span class="nav-text">sklearn各功能实现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#数据预处理"><span class="nav-number">2.1.</span> <span class="nav-text">数据预处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#特征工程"><span class="nav-number">2.2.</span> <span class="nav-text">特征工程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#构建有监督模型"><span class="nav-number">2.3.</span> <span class="nav-text">构建有监督模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#构建无监督模型"><span class="nav-number">2.4.</span> <span class="nav-text">构建无监督模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#评估模型"><span class="nav-number">2.5.</span> <span class="nav-text">评估模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#其他"><span class="nav-number">2.6.</span> <span class="nav-text">其他</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pipeline构建"><span class="nav-number">2.7.</span> <span class="nav-text">Pipeline构建</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参数验证"><span class="nav-number">2.8.</span> <span class="nav-text">参数验证</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分类数据进行绘图"><span class="nav-number">2.9.</span> <span class="nav-text">分类数据进行绘图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型保存"><span class="nav-number">2.10.</span> <span class="nav-text">模型保存</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tips"><span class="nav-number">2.11.</span> <span class="nav-text">tips</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#还有一些东西没来得及总计，有机会再补充"><span class="nav-number">2.12.</span> <span class="nav-text">还有一些东西没来得及总计，有机会再补充</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-car"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WenchaoXiu</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
