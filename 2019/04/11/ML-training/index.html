<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="ML, Python, R, Algorithms" />





  <link rel="alternate" href="/atom.xml" title="WenchaoXiu" type="application/atom+xml" />






<meta name="description" content="机器学习库使用总结">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习库使用总结">
<meta property="og:url" content="http://WenchaoXiu.github.io/2019/04/11/ML-training/index.html">
<meta property="og:site_name" content="WenchaoXiu">
<meta property="og:description" content="机器学习库使用总结">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://wenchaoxiu.github.io/images/pandas_commands/p1.png">
<meta property="og:image" content="http://wenchaoxiu.github.io/images/pandas_commands/p2.png">
<meta property="og:image" content="http://wenchaoxiu.github.io/images/pandas_commands/p3.png">
<meta property="og:image" content="http://wenchaoxiu.github.io/images/pandas_commands/p4.png">
<meta property="og:image" content="http://wenchaoxiu.github.io/images/pandas_commands/p5.png">
<meta property="og:image" content="http://wenchaoxiu.github.io/images/pandas_commands/p6.png">
<meta property="og:image" content="http://wenchaoxiu.github.io/images/pandas_commands/p7.png">
<meta property="og:image" content="http://wenchaoxiu.github.io/images/pandas_commands/p8.png">
<meta property="og:image" content="http://wenchaoxiu.github.io/images/pandas_commands/p9.png">
<meta property="og:updated_time" content="2019-07-03T15:15:01.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习库使用总结">
<meta name="twitter:description" content="机器学习库使用总结">
<meta name="twitter:image" content="http://wenchaoxiu.github.io/images/pandas_commands/p1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://WenchaoXiu.github.io/2019/04/11/ML-training/"/>





  <title>机器学习库使用总结 | WenchaoXiu</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">WenchaoXiu</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">just try blog</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://WenchaoXiu.github.io/2019/04/11/ML-training/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="WenchaoXiu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/head.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WenchaoXiu">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器学习库使用总结</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-11T10:45:53+08:00">
                2019-04-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数据分析-工具应用/" itemprop="url" rel="index">
                    <span itemprop="name">数据分析,工具应用</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          
              <div class="post-description">
                  机器学习库使用总结
              </div>
          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p class="description"></p>


<a id="more"></a>
<h1 id="jupyter-notebook技巧"><a href="#jupyter-notebook技巧" class="headerlink" title="jupyter notebook技巧"></a><font color="red">jupyter notebook技巧</font></h1><h2 id="1-安装jupyter-notbook及其扩展"><a href="#1-安装jupyter-notbook及其扩展" class="headerlink" title="1. 安装jupyter notbook及其扩展"></a>1. 安装jupyter notbook及其扩展</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda install jupyter notebook <span class="comment"># 安装anaconda之后，下载jupyter notebook</span></span><br><span class="line">conda install -c conda-forge jupyter_contrib_nbextensions <span class="comment"># jupyter notebook扩展安装</span></span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple autopep8 <span class="comment"># 代码自动规范化包</span></span><br></pre></td></tr></table></figure>
<p><a href="https://zhuanlan.zhihu.com/p/52890101" target="_blank" rel="noopener">jupyter extension使用参考</a></p>
<h2 id="2-jupyter使用设置"><a href="#2-jupyter使用设置" class="headerlink" title="2. jupyter使用设置"></a>2. jupyter使用设置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置输入输出情况</span></span><br><span class="line"><span class="keyword">from</span> IPython.core.interactiveshell <span class="keyword">import</span> InteractiveShell</span><br><span class="line">InteractiveShell.ast_node_interactivity = <span class="string">'all'</span>/<span class="string">'last_expr'</span></span><br><span class="line"><span class="comment"># matplotlib画图显示</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="comment"># 使用bash命令</span></span><br><span class="line">!head -n <span class="number">5</span> xx.txt</span><br><span class="line">!ls -ltrh *</span><br></pre></td></tr></table></figure>
<h2 id="3-pyhton2-python3-kernel共存"><a href="#3-pyhton2-python3-kernel共存" class="headerlink" title="3. pyhton2 python3 kernel共存"></a>3. pyhton2 python3 kernel共存</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span> 安装anaconda3</span><br><span class="line"><span class="number">2.</span> conda create -n py27 python=<span class="number">2.7</span></span><br><span class="line"><span class="number">3.</span> source activate py27</span><br><span class="line"><span class="number">4.</span> conda install -n py27 ipykernel</span><br><span class="line"><span class="number">5.</span> python -m ipykernel install --user --name py27 --display-name <span class="string">"python2"</span></span><br></pre></td></tr></table></figure>
<h2 id="4-本地访问远端服务器"><a href="#4-本地访问远端服务器" class="headerlink" title="4. 本地访问远端服务器"></a>4. 本地访问远端服务器</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sever端</span></span><br><span class="line">jupyter notebook --allow-root --port=8889 --no-browser</span><br><span class="line"><span class="comment"># local端</span></span><br><span class="line">ssh -f -N -L localhost:8000:localhost:8889 xxx@xx.xx.xx.xx -p 6666</span><br><span class="line"><span class="comment"># 打开网页</span></span><br><span class="line">http://localhost:8000</span><br></pre></td></tr></table></figure>
<h1 id="Python包Pandas学习笔记"><a href="#Python包Pandas学习笔记" class="headerlink" title="Python包Pandas学习笔记"></a><font color="red">Python包Pandas学习笔记</font></h1><p><strong>最近对pandas做了一个系统的学习，主要参考了这套<a href="https://github.com/guipsamora/pandas_exercises" target="_blank" rel="noopener">习题</a>，方便后续进行python数据分析</strong></p>
<h2 id="1-package的载入"><a href="#1-package的载入" class="headerlink" title="1 package的载入"></a>1 package的载入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<h2 id="2-数据读取-“-”暂作“或”使用"><a href="#2-数据读取-“-”暂作“或”使用" class="headerlink" title="2 数据读取(“/”暂作“或”使用)"></a>2 数据读取(“/”暂作“或”使用)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># \s+是利用空白符进行分割,可使用正则表达式匹配</span></span><br><span class="line"><span class="comment"># header可以制定列明对应的行数，如果没有就是None</span></span><br><span class="line"><span class="comment"># index_col就是行名对应的列数，如果没有也是None</span></span><br><span class="line"><span class="comment"># parse_dates日期型列</span></span><br><span class="line">pd.read_csv(path, sep=<span class="string">'\s+'</span>/<span class="string">'\t'</span>/<span class="string">','</span>, header=<span class="number">0</span>/<span class="keyword">None</span>, usecols=[...], </span><br><span class="line">	,parse_dates=[<span class="number">0</span>]/[<span class="string">'Date'</span>], index_col=<span class="number">0</span>/<span class="keyword">None</span>, encoding=<span class="string">'utf-8'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="3-数据输出"><a href="#3-数据输出" class="headerlink" title="3 数据输出"></a>3 数据输出</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># na_rep是填充的缺失值</span></span><br><span class="line"><span class="comment"># header可以给一个list用作数据输出的列名</span></span><br><span class="line"><span class="comment"># columns可以给定数字list用于选取输出特定的列</span></span><br><span class="line">pd.to_csv(path, sep=<span class="string">''</span>, na_rep=<span class="string">'NA'</span>, header=<span class="keyword">True</span>/[<span class="string">'xx'</span>,<span class="string">'xx'</span>], index=<span class="keyword">True</span>, </span><br><span class="line">	columns=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3.</span>.], encoding=<span class="string">'utf-8'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="4-创建DataFrame-Series对象"><a href="#4-创建DataFrame-Series对象" class="headerlink" title="4 创建DataFrame,Series对象"></a>4 创建DataFrame,Series对象</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DataFrame和Series都接受list和numpy array数据，若要转换回array可以用df.values或S.values</span></span><br><span class="line"><span class="comment"># DataFrame还可以接受dictionary对象</span></span><br><span class="line">df = pd.DataFrame(np.random.rand(<span class="number">10</span>,<span class="number">5</span>), columns=list(<span class="string">'ABCDE'</span>)) <span class="comment">#列名为ABCDE</span></span><br><span class="line">S = pd.Series([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br></pre></td></tr></table></figure>
<h2 id="5-数据类型总结"><a href="#5-数据类型总结" class="headerlink" title="5 数据类型总结"></a>5 数据类型总结</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(&#123;<span class="string">'string'</span>: list(<span class="string">'abc'</span>),</span><br><span class="line">                   <span class="string">'int64'</span>: list(range(<span class="number">1</span>, <span class="number">4</span>)),</span><br><span class="line">                   <span class="string">'uint8'</span>: np.arange(<span class="number">3</span>, <span class="number">6</span>).astype(<span class="string">'u1'</span>),</span><br><span class="line">                   <span class="string">'float64'</span>: np.arange(<span class="number">4.0</span>, <span class="number">7.0</span>),</span><br><span class="line">                   <span class="string">'bool1'</span>: [<span class="keyword">True</span>, <span class="keyword">False</span>, <span class="keyword">True</span>],</span><br><span class="line">                   <span class="string">'bool2'</span>: [<span class="keyword">False</span>, <span class="keyword">True</span>, <span class="keyword">False</span>],</span><br><span class="line">                   <span class="string">'dates'</span>: pd.date_range(<span class="string">'now'</span>, periods=<span class="number">3</span>).values,</span><br><span class="line">                   <span class="string">'category'</span>: pd.Series(list(<span class="string">"ABC"</span>)).astype(<span class="string">'category'</span>)&#125;)</span><br><span class="line">S.astype(np.int64) <span class="comment"># 数据类型转化</span></span><br><span class="line">S.dtype == np.int64 <span class="comment"># 数据类型判断</span></span><br><span class="line">S.to_frame() <span class="comment"># 将Series数据转换为DataFrame数据</span></span><br><span class="line">pd.to_datetime(df.a) <span class="comment"># 将df数据a列转换为datetime类型</span></span><br><span class="line">pd.to_numeric(aDF.loc[:, <span class="string">'xxx'</span>])  <span class="comment">#转换成数字</span></span><br></pre></td></tr></table></figure>
<h2 id="6-查看数据"><a href="#6-查看数据" class="headerlink" title="6 查看数据"></a>6 查看数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">df.head(<span class="number">10</span>) <span class="comment"># 查看数据前10行</span></span><br><span class="line">df.tail(<span class="number">10</span>) <span class="comment"># 查看数据后10行</span></span><br><span class="line">df.shape <span class="comment"># 数据对应的行列数</span></span><br><span class="line">df.info() <span class="comment"># 数据索引，类型，内存信息</span></span><br><span class="line">df.describe(include=<span class="string">'all'</span>) <span class="comment"># 对于数字型数据进行分位数统计,all代表对所有数据类型统计</span></span><br><span class="line">S.value_counts(dropna=<span class="keyword">False</span>) <span class="comment"># 对Series里面的值进行个数统计，NA也会统计</span></span><br><span class="line">df.apply(pd.Series.value_counts) <span class="comment">#返回每个值在各列中的个数，没有则用NaN代替</span></span><br><span class="line">df.index <span class="comment"># 返回数据的索引</span></span><br><span class="line">df.columns <span class="comment"># 返回数据的列名</span></span><br><span class="line">df.mean()/min()/median()/std()/count() <span class="comment"># 分别是df的列均值,最小值,中位数,标准差,非空值</span></span><br><span class="line">df.corr() <span class="comment"># 列之间的相关系数</span></span><br><span class="line">df.idxmax(<span class="number">0</span>) <span class="comment"># 每列最大数对应行的index的名</span></span><br><span class="line">df.idxmax(<span class="number">1</span>) <span class="comment"># 每行最大数对应的列名</span></span><br><span class="line">aDF.nsmallest(columns=<span class="string">'age'</span>, n=<span class="number">20</span>) <span class="comment"># 取出年龄最小的20个数据</span></span><br><span class="line">S.is_unique <span class="comment"># 确定Series数据是否是unique的, 返回bool值</span></span><br></pre></td></tr></table></figure>
<h2 id="7-数据的截取"><a href="#7-数据的截取" class="headerlink" title="7 数据的截取"></a>7 数据的截取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">df.xxx / df[<span class="string">'xxx'</span>] <span class="comment"># 返回数据的某一列，列名为xxx，类型为Series</span></span><br><span class="line">df[[<span class="string">'xx'</span>,<span class="string">'yy'</span>]] <span class="comment"># 选取多列数据，类型为DataFrame</span></span><br><span class="line">df.iloc[<span class="number">3</span>] <span class="comment"># 选取第4行数据</span></span><br><span class="line">df.iloc[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],:] <span class="comment"># 选取多行数据</span></span><br><span class="line">df.loc[[<span class="string">'x'</span>,<span class="string">'y'</span>,<span class="string">'z'</span>],[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>]] <span class="comment">#根据行index名和列名进行数据截取</span></span><br><span class="line">df.ix[..,..] <span class="comment"># ix是用行名列名以及行数列数混合赋值的情况下数据的截取</span></span><br><span class="line">df[(df.col&gt;<span class="number">0.5</span>) &amp; (df.col&lt;<span class="number">10</span>)] <span class="comment"># 筛选col大于0.5小于10的行返回</span></span><br><span class="line">aDF.loc[(aDF[<span class="string">'a'</span>]&gt;<span class="number">10</span>) &amp; (aDF[<span class="string">'b'</span>]&lt;<span class="number">100</span>), :] <span class="comment"># 也可以给条件进行筛选,&amp; | ~进行逻辑运算</span></span><br><span class="line">df.values <span class="comment"># 返回df对应的numpy array值</span></span><br><span class="line">df.values[<span class="number">10</span>][<span class="number">5</span>] <span class="comment">#求df数据11行6列的值</span></span><br><span class="line">df[df[<span class="string">'xxx'</span>].notnull(), :] = <span class="number">10</span> <span class="comment"># 对空值赋值</span></span><br><span class="line">S.str.startswith(<span class="string">'G'</span>) <span class="comment"># Seriers以G开头的字符, 返回bool值</span></span><br><span class="line">S.isin([<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>]) <span class="comment"># 返回bool值如果S在list['a','b','c']中, 返回true</span></span><br><span class="line">S != <span class="string">'xxx'</span> <span class="comment"># Series中不为xxx的位置, 返回bool值</span></span><br></pre></td></tr></table></figure>
<h2 id="8-数据清洗"><a href="#8-数据清洗" class="headerlink" title="8 数据清洗"></a>8 数据清洗</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">del</span> df[<span class="string">'a'</span>] <span class="comment">#删除数据df的a列</span></span><br><span class="line">df.drop([<span class="string">'B'</span>,<span class="string">'C'</span>],axis=<span class="number">1</span>,inplace=<span class="keyword">True</span>) <span class="comment"># 删除数据df的B,C列, 在原数据上进行修改</span></span><br><span class="line">df.dropna(how = <span class="string">'all'</span>, axis=<span class="number">0</span>) <span class="comment"># 对行进行操作,如果一行里面全都是na那么就删除,如果要一列里面全是na就删除,那么axis=1df.loc[:, 'newcol'] = 2000 # 如果没有newcol那么就新加一列</span></span><br><span class="line">df.columns = [<span class="string">'a'</span>,<span class="string">'b'</span>] <span class="comment"># 更改数据的列名</span></span><br><span class="line">df.isnull().sum() <span class="comment"># 统计各列中缺失值的个数</span></span><br><span class="line">df.notnull().sum() <span class="comment"># 统计各列中非缺失值的个数</span></span><br><span class="line">df.drop_duplicates([...], <span class="string">'first'</span>/<span class="string">'last'</span>/<span class="keyword">False</span>) </span><br><span class="line"><span class="comment"># 移除重复项, list可以是列名也可以是数字序列,first是保留重复中的第一个, last是保留重复中的最后一个, False一个不留, 只要重复都删除</span></span><br><span class="line">df.dropna(axis=<span class="number">0</span>/<span class="number">1</span>, how=<span class="string">'any'</span>/<span class="string">'all'</span>, thresh=n)</span><br><span class="line"><span class="comment"># 移除数据中的缺失行,axis0是行删除,1是列删除</span></span><br><span class="line"><span class="comment"># any是只要有一个就删除,all是所有的都是才删除</span></span><br><span class="line"><span class="comment"># thresh目的是大于n个NA才删除</span></span><br><span class="line">S.fillna(x) <span class="comment"># 对确实值进行填充,填充值为x</span></span><br><span class="line">aDF.loc[:,<span class="string">'xx'</span>].fillna(aSeires) <span class="comment"># 对数据进行填充,根据aSeires的index和aDF的index进行填充</span></span><br><span class="line">S.astype(np.float) <span class="comment"># 数据的类型转换</span></span><br><span class="line">S.replace(<span class="number">1</span>, <span class="string">'one'</span>) <span class="comment"># 将1替换为'one'</span></span><br><span class="line">S.replace([<span class="number">1</span>,<span class="number">2</span>], [<span class="string">'one'</span>,<span class="string">'two'</span>]) <span class="comment"># 将1替换为one, 2替换为two</span></span><br><span class="line">df.rename(index/columns=&#123;<span class="string">'old1'</span>:<span class="string">'new1'</span>,<span class="string">'old2'</span>:<span class="string">'new2'</span>&#125;) <span class="comment"># 修改行名列名，将old1改为new1，将old2改为new2</span></span><br><span class="line">df.set_index(<span class="string">'B'</span>) <span class="comment"># 修改index，将B所在的列作为行索引</span></span><br><span class="line">df.sort_index() <span class="comment"># 将数据按照index进行排序</span></span><br><span class="line">df.sort_values([col1, col2], ascending=[<span class="keyword">True</span>,<span class="keyword">False</span>]) <span class="comment"># 根据col1和col2的值进行排序，col1是升序，col2是降序</span></span><br><span class="line">S.argsort() <span class="comment"># 返回Series对应的值的order，S[S.argsort()]返回的是对应的从小到大的Series数值</span></span><br><span class="line">df.reset_index(drop=<span class="keyword">False</span>/<span class="keyword">True</span>, inplace=<span class="keyword">False</span>/<span class="keyword">True</span>) <span class="comment"># 数据的index换成从0开始的, drop是说是否保留原来的index, 保留的话就多一列, inplace是说是否修改原来的df</span></span><br><span class="line">data[<span class="string">'Age'</span>] = pd.cut(data[<span class="string">'Age'</span>], bins=<span class="number">6</span>, labels=np.arange(<span class="number">6</span>)) <span class="comment"># 对数值型数据进行区间分割，分割成6个bin，label用0-5表示</span></span><br><span class="line">np.tile(a, N).flatten() <span class="comment"># 对数据a进行重复</span></span><br></pre></td></tr></table></figure>
<h2 id="9-数据分组"><a href="#9-数据分组" class="headerlink" title="9 数据分组"></a>9 数据分组</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">df.groupby(col).size() <span class="comment"># 按照col对数据进行分组，并计算每一组的数量, 如果是count的话每列都会计算一次分组后的数量, 比较冗余</span></span><br><span class="line">df.groupby([col1, col2]).mean() <span class="comment"># 按照col1,col2进行分组，并计算各组的均值</span></span><br><span class="line">df.groupby([col1, col2]).agg([<span class="string">'min'</span>, <span class="string">'max'</span>, <span class="string">'mean'</span>]) <span class="comment"># 按照col1col2进行分组，计算各组之间的min, max, mean</span></span><br><span class="line">df.groupby([col1, col2]).agg(&#123;<span class="string">'a'</span>:<span class="string">'min'</span>, <span class="string">'b'</span>:<span class="string">'max'</span>, <span class="string">'c'</span>:<span class="string">'mean'</span>&#125;) <span class="comment"># 按照col1col2进行分组，计算各组之间的a列的min, b列的max, c列的mean</span></span><br><span class="line">df.groupby(col1)[col2].mean() <span class="comment"># 计算按照col1分组的col2对应的均值</span></span><br><span class="line">df.pivot.table(index=col1, values=[col2, col3], aggfun=<span class="string">'mean'</span>) <span class="comment"># 以col1的值为index,以col2,col3值为列进行分组计算各元素平均值</span></span><br><span class="line">df.apply(np.mean) <span class="comment"># 计算每一列的平均值</span></span><br><span class="line">df.apply(np.max, axis=<span class="number">1</span>) <span class="comment">#计算每一行的平均值</span></span><br><span class="line">df.applymap(<span class="keyword">lambda</span> x : x.upper()) <span class="comment"># 对多列数据操作, 这里是对各列都大写</span></span><br><span class="line"><span class="keyword">for</span> name,data <span class="keyword">in</span> df.groupby(<span class="string">'col'</span>):</span><br><span class="line">	<span class="keyword">print</span> name <span class="comment"># col列分类后的值</span></span><br><span class="line">	<span class="keyword">print</span> data <span class="comment"># col列名称等于name对应的数据行</span></span><br><span class="line">df.groupby(<span class="string">'name'</span>).apply(ownfunc) <span class="comment"># 可以对不同组进行自定义函数操作</span></span><br></pre></td></tr></table></figure>
<h2 id="10-数据合并"><a href="#10-数据合并" class="headerlink" title="10 数据合并"></a>10 数据合并</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">df1.append([df2, df3])  <span class="comment"># 也可以追加两个DF</span></span><br><span class="line">pd.concat([df1.set_index(<span class="string">'a'</span>), df2.set_index(<span class="string">'a'</span>)], sort=<span class="keyword">False</span>, axis=<span class="number">1</span>, join=<span class="string">'inner'</span>) <span class="comment"># 和上述利用merge在a字段上进行内连接的效果类似,因为concat是基于index进行连接的,merge可以不基于index,指定字段</span></span><br><span class="line">pd.concat([df1, df2], axis=<span class="number">1</span>) <span class="comment">#列数相同, 行合在一起</span></span><br><span class="line">pd.concat(frames, keys=[<span class="string">'x'</span>, <span class="string">'y'</span>, <span class="string">'z'</span>], axis=<span class="number">0</span>) <span class="comment">#行数相同, 列合在一起, 每个数据的来源分别标注xyz</span></span><br><span class="line">pd.merge(df1, df2, on=[<span class="string">'key1'</span>,<span class="string">'key2'</span>], how=<span class="string">'outer'</span>/<span class="string">'inner'</span>/<span class="string">'left'</span>/<span class="string">'right'</span>) <span class="comment"># 合并df1和df2,根据df1的key1和df2的key2, 连接方式是外链接..</span></span><br><span class="line">pd.merge(df1, df2, how=<span class="string">'inner'</span>, left_index=<span class="keyword">True</span>, right_on=<span class="string">'id'</span>) <span class="comment"># 对数据进行merge,左表以index作为连接关键字,右表用id作为关键字</span></span><br><span class="line">np.vstack((a,b)) <span class="comment"># 乱入一个numpy合并用法，行合并</span></span><br><span class="line"><span class="comment"># pd.join与merge用法类似, 只不过默认是left链接, merge是inner连接</span></span><br></pre></td></tr></table></figure>
<div style="display: none"><br>### 2.1 div的用法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">users = pd.read_table(<span class="string">'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'</span>, </span><br><span class="line">        	sep=<span class="string">'|'</span>, index_col=<span class="string">'user_id'</span>)</span><br><span class="line">total = users.groupby([<span class="string">'occupation'</span>]).gender.count() <span class="comment"># 计算occupation的对应的人数</span></span><br><span class="line">gender = users.groupby([<span class="string">'occupation'</span>,<span class="string">'gender'</span>]).gender.count() <span class="comment"># 计算各职业各性别的人数</span></span><br><span class="line">(gender.div(total, level=<span class="string">'occupation'</span>)*<span class="number">100</span>).unstack() <span class="comment">#计算各职业的各性别的百分比</span></span><br></pre></td></tr></table></figure><br><br></div>

<h2 id="11-时序数据操作"><a href="#11-时序数据操作" class="headerlink" title="11 时序数据操作"></a>11 时序数据操作</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">df.index = pd.date_range(<span class="string">'2018/1/1'</span>, period=df.shape[<span class="number">0</span>]) <span class="comment"># 添加时间序列作为行名</span></span><br><span class="line">pd.to_datetime(df.a, format=<span class="string">'%Y'</span>) <span class="comment"># 将df的a列转化成datetime类型的年</span></span><br><span class="line">pd.to_datetime(<span class="number">1490195805</span>, unit=<span class="string">'s'</span>) <span class="comment"># 对UNIX时间进行时间转换</span></span><br><span class="line">df[<span class="string">'a'</span>].to_datetime().year/month/day <span class="comment"># df的a列转换为datetime类型之后提取其中的year或者month或者day</span></span><br><span class="line">(df[<span class="string">'a'</span>].to_datetime().max() - df[<span class="string">'a'</span>].to_datetime().min()).days <span class="comment"># 计算a列中最早最晚时间差</span></span><br><span class="line">df[<span class="string">'Date'</span>].dt.dayofweek <span class="comment"># 获取每周第几天</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> datetime <span class="keyword">as</span> dt</span><br><span class="line">dt.datetime(<span class="number">2015</span>,<span class="number">1</span>,<span class="number">1</span>) <span class="comment"># 通过datetime包定义数据时间</span></span><br><span class="line">dt.datetime.today() <span class="comment"># 返回今天对应的时间</span></span><br><span class="line"></span><br><span class="line">df.resample(<span class="string">'10AS'</span>).sum() </span><br><span class="line"><span class="comment"># downsample时序数据, 频率是每10年算各列的加和, S是index从1月1日开始, 不加S则从12月30日开始</span></span><br><span class="line"><span class="comment"># resample的各个字符含义: A-year, M-month, W-week, D-day, H-hour, T-minute, S-second</span></span><br></pre></td></tr></table></figure>
<p>除了downsample也可以upsample需要插值, 具体使用参考<a href="https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.resample.html" target="_blank" rel="noopener">官方文档</a></p>
<h1 id="绘图命令"><a href="#绘图命令" class="headerlink" title="绘图命令"></a><font color="red">绘图命令</font></h1><h2 id="1-pandas内置绘图"><a href="#1-pandas内置绘图" class="headerlink" title="1. pandas内置绘图"></a>1. pandas内置绘图</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df.plot.bar() <span class="comment"># barplot, stacked=True, 堆叠</span></span><br><span class="line">df.plot.barh() <span class="comment"># 绘制水平的barplot</span></span><br><span class="line">df.plot.hist(bins = <span class="number">20</span>) <span class="comment"># 绘制直方图,单维度</span></span><br><span class="line">df.plot.box() <span class="comment"># 对每列去看一些分布outlier</span></span><br><span class="line">df.plot.area() <span class="comment"># 堆叠区域图</span></span><br><span class="line">df.plot.scatter(x=<span class="string">'a'</span>, y=<span class="string">'b'</span>) <span class="comment"># 散点图</span></span><br><span class="line">df.plot.pie(subplots=<span class="keyword">True</span>) <span class="comment"># 绘制带图例的饼图</span></span><br></pre></td></tr></table></figure>
<h2 id="2-matplotlib绘图的一些设置"><a href="#2-matplotlib绘图的一些设置" class="headerlink" title="2. matplotlib绘图的一些设置"></a>2. matplotlib绘图的一些设置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">8</span>)) <span class="comment"># 设置画布大小</span></span><br><span class="line">plt.xticks([<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>], [<span class="string">r'a'</span>,<span class="string">r'b'</span>,<span class="string">r'c'</span>]) <span class="comment"># 设置坐标轴刻度</span></span><br><span class="line">plt.xlim(<span class="number">1</span>,<span class="number">3</span>) <span class="comment"># 设置坐标位置</span></span><br><span class="line">plt.title() <span class="comment"># 标题</span></span><br><span class="line">plt.xlabel(<span class="string">'xxx'</span>, fontsize=<span class="number">18</span>) <span class="comment"># 绘制label</span></span><br><span class="line">plt.text(<span class="number">0.8</span>, <span class="number">0.9</span>, <span class="string">'xxx'</span>, color=<span class="string">'k'</span>, fontsize=<span class="number">15</span>) <span class="comment"># 进行注解</span></span><br><span class="line">plt.grid(<span class="keyword">True</span>) <span class="comment"># 网格线</span></span><br></pre></td></tr></table></figure>
<h2 id="3-seaborn绘图"><a href="#3-seaborn绘图" class="headerlink" title="3. seaborn绘图"></a>3. seaborn绘图</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">- sns.displot(x, kde=<span class="keyword">True</span>, bins=<span class="number">20</span>, rug=<span class="keyword">True</span>, fit=stats.gamma) <span class="comment"># histgram加密度线,样本分布情况, 拟合某些分布fit</span></span><br><span class="line">- sns.kdeplot <span class="comment"># 类似于上面的,kde是每个样本用正态分布画,如果样本多,高度就高,之后再做归一化</span></span><br><span class="line">- sns.jointplot(x,y,data) <span class="comment"># 绘制带有histgram以及散点图的图，两个变量</span></span><br><span class="line">- sns.pairplot(df) <span class="comment"># 直接绘制各个列之间的散点图以及对应的histgram，多个变量</span></span><br><span class="line">- 多图绘制<span class="number">1</span></span><br><span class="line">  g = sns.PairGrik(df) <span class="comment"># 各个列混合,产出n*n个格子</span></span><br><span class="line">  g.map_diag(sns.kdeplot) <span class="comment"># 对角线绘制</span></span><br><span class="line">  g.map_offdiag(sns.kdeplot, cmap=<span class="string">'Blues_d'</span>, n_levels=<span class="number">20</span>) <span class="comment"># 绘制对角线是kde密度图其他为等高线的图</span></span><br><span class="line">- 多图绘制<span class="number">2</span></span><br><span class="line">  g = FaceGrid(row=[..],aspect=<span class="number">1.5</span>, data=)</span><br><span class="line">  g.map(sns.boxplot, x, y, hue, hue_order=[], ...)</span><br><span class="line">- 多图绘制<span class="number">3</span></span><br><span class="line">  g = sns.PairGrid(data, x_vars=[], y_vars=[], aspect=<span class="number">0.5</span>, size=<span class="number">3.5</span>)</span><br><span class="line">  g.map(sns.violinplot, palette=<span class="string">'bright'</span>) <span class="comment"># x_vars数量*y_vars数量个子图，然后每个子图都绘制violinplot</span></span><br><span class="line">- 关联分析 sns.lmplot</span><br><span class="line">  · sns.lmplot(x, y, data) <span class="comment"># 散点图+线性回归,95%置信区间,适用于连续值</span></span><br><span class="line">- sns.residplot() <span class="comment"># 残差图</span></span><br><span class="line">- sns.barplot(x,y,hue,ci=<span class="keyword">None</span>)  <span class="comment"># 是否打开置信区间</span></span><br><span class="line">- sns.stripplot(x, y, data, jitter =<span class="keyword">True</span>) <span class="comment"># 基于x为离散数据的,类似于散点图的boxplot</span></span><br><span class="line">- sns.swarmplot(x, y, data) <span class="comment">#  蜂群图，类似于小提琴图的点版</span></span><br><span class="line">- sns.boxplot()</span><br><span class="line">- sns.violinplot(bw) <span class="comment"># 属于kde以及boxplot的组合，既看了单变量分布，也看了各变量之间的差异</span></span><br><span class="line">- sns.violinplot(split=<span class="keyword">True</span>， hue， inner=<span class="string">'stick'</span>) <span class="comment"># split将hue为两个类型的进行拼接绘制小提琴图，stick，每个样本绘制竖线</span></span><br><span class="line">- sns.countplot(x, data) <span class="comment"># 绘制离散变量数量分布，类似于value_counts()，类似于barplot但是使用的统计量是数量</span></span><br><span class="line">- sns.pointplot(x, y, hue) <span class="comment"># 查看离散变量x以及hue在离散变量y上的差别，使用均值，画点</span></span><br><span class="line">- sns.factorplot(x, y, hue, col, data, kind=<span class="string">'swarm'</span>) <span class="comment"># 是一种泛化的绘图函数</span></span><br><span class="line">- a.savefig(<span class="string">'xx'</span>) <span class="comment"># 进行图片存储 plt函数</span></span><br></pre></td></tr></table></figure>
<h2 id="4-一些图形实例"><a href="#4-一些图形实例" class="headerlink" title="4. 一些图形实例"></a>4. 一些图形实例</h2><h3 id="4-1-barplot"><a href="#4-1-barplot" class="headerlink" title="4.1 barplot"></a>4.1 barplot</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 绘图包的载入</span></span><br><span class="line">% matplotlib inline <span class="comment"># 内嵌画图, 有这个命令就可以省去plt.show()</span></span><br><span class="line">Series.plot(kind = <span class="string">'bar'</span>) <span class="comment"># 绘制条形图</span></span><br><span class="line">plt.xlabel(<span class="string">'xxx'</span>) <span class="comment"># 加x轴label</span></span><br><span class="line">plt.ylabel(<span class="string">'yyy'</span>) <span class="comment"># 加y轴label</span></span><br><span class="line">plt.title(<span class="string">'zzz'</span>) <span class="comment"># 加标题</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/pandas_commands/p1.png" alt="p1"></p>
<h3 id="4-2-scatter-plot"><a href="#4-2-scatter-plot" class="headerlink" title="4.2 scatter plot"></a>4.2 scatter plot</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(x, y, s=size, c=<span class="string">'green'</span>) <span class="comment"># 绘制散点图, s表明点大小, c表示点的颜色, 这两个参数都可以是list</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/pandas_commands/p2.png" alt="p2"></p>
<h3 id="4-3-pie-chart"><a href="#4-3-pie-chart" class="headerlink" title="4.3 pie chart"></a>4.3 pie chart</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.pie([...], labels=[...], colors=[...], explode=(...), startangle=<span class="number">90</span>) <span class="comment"># 饼图的参数都是list, explode参数是为了让饼图不同类之间有空隙的参数</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/pandas_commands/p3.png" alt="p3"></p>
<h3 id="4-4-分组scatter-plot"><a href="#4-4-分组scatter-plot" class="headerlink" title="4.4 分组scatter plot"></a>4.4 分组scatter plot</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.lmplot(x=<span class="string">'age'</span>, y=<span class="string">'Fare'</span>, data=df, hue=<span class="string">'sex'</span>, fit_reg=<span class="keyword">False</span>) <span class="comment"># 绘制以age和Fare为xy轴的散点图, 以性别分类</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/pandas_commands/p4.png" alt="p4"></p>
<h3 id="4-5-histgram"><a href="#4-5-histgram" class="headerlink" title="4.5 histgram"></a>4.5 histgram</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.hist(S, bins=np.arange(<span class="number">0</span>, <span class="number">600</span>, <span class="number">10</span>)) <span class="comment"># 绘制直方图, bin可以自己定义</span></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">a = sns.dstplot(S) <span class="comment"># 绘制直方图, 带一条正态拟合曲线</span></span><br><span class="line">a.set(xlabel=<span class="string">''</span>, ylabel=<span class="string">''</span>, title=<span class="string">''</span>) <span class="comment"># 设定label</span></span><br><span class="line">sns.despline() <span class="comment"># 去掉右侧上侧的边框</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/pandas_commands/p5.png" alt="p5"></p>
<h3 id="4-6-correlation-plot"><a href="#4-6-correlation-plot" class="headerlink" title="4.6 correlation plot"></a>4.6 correlation plot</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.jointplot(x=<span class="string">''</span>, y=<span class="string">''</span>, data=df) <span class="comment">#绘制带correlation散点图+histgram</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/pandas_commands/p6.png" alt="p6"></p>
<h3 id="4-7-pairwise散点图"><a href="#4-7-pairwise散点图" class="headerlink" title="4.7 pairwise散点图"></a>4.7 pairwise散点图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.pairplot(df) <span class="comment"># 多列数据绘制散点图</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/pandas_commands/p7.png" alt="p7"></p>
<h3 id="4-8-分类boxplot图"><a href="#4-8-分类boxplot图" class="headerlink" title="4.8 分类boxplot图"></a>4.8 分类boxplot图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.boxplot(x=<span class="string">''</span>, y=<span class="string">''</span>, data=df, hue=<span class="string">''</span>) <span class="comment"># 分类box plot, hue是类别</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/pandas_commands/p8.png" alt="p8"></p>
<h3 id="4-9-分类boxplot点图"><a href="#4-9-分类boxplot点图" class="headerlink" title="4.9 分类boxplot点图"></a>4.9 分类boxplot点图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.stripplot(x=<span class="string">''</span>, y=<span class="string">''</span>, data=df, hue=<span class="string">'sex'</span>, jitter=<span class="keyword">True</span>...) </span><br><span class="line"><span class="comment"># 绘制类似于boxplot的图，只不过画的是每个box里面的点, x轴是不同数据类</span></span><br></pre></td></tr></table></figure>
<p><img src="/images/pandas_commands/p9.png" alt="p9"></p>
<h1 id="大数据知识"><a href="#大数据知识" class="headerlink" title="大数据知识"></a><font color="red">大数据知识</font></h1><h2 id="1-hadoop"><a href="#1-hadoop" class="headerlink" title="1. hadoop"></a>1. hadoop</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /input/example1 <span class="comment"># 将用于处理的文件上传到集群中，集群自动分配</span></span><br><span class="line">hadoop fs -put text* /input/example1 <span class="comment"># 查看文件是否放好</span></span><br><span class="line">hadoop fs -ls /input/example1 <span class="comment"># 集群上跑任务</span></span><br><span class="line">hadoop jar /usr/lib/hadoop-current/share/hadoop/tools/lib/hadoop-streaming-2.7.2.jar \</span><br><span class="line">  -file count_mapper.py \ <span class="comment"># 将这个文件传到集群上一会会使用</span></span><br><span class="line">  -mapper count_mapper.py \ <span class="comment"># 将这个文件充当mapper处理</span></span><br><span class="line">  -file count_reducer.py \</span><br><span class="line">  -reducer count_reducer.py \</span><br><span class="line">  -input /input/example1 \ <span class="comment"># 以终端的方式将文件一个个的传给命令</span></span><br><span class="line">  -output /output/example1 </span><br><span class="line">hadoop fs -getmerge /output/example1 result.txt <span class="comment"># 运行成功之后将结果拉下来，将hadoop执行完成的结果存在/output/</span></span><br></pre></td></tr></table></figure>
<h2 id="2-pyspark-基于spark"><a href="#2-pyspark-基于spark" class="headerlink" title="2. pyspark(基于spark)"></a>2. pyspark(基于spark)</h2><h3 id="2-1-初始化RDD的方法"><a href="#2-1-初始化RDD的方法" class="headerlink" title="2.1 初始化RDD的方法"></a>2.1 初始化RDD的方法</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">- 第一种方式直接通过内置的数据类型进行读取</span><br><span class="line">  import pyspark</span><br><span class="line">  form pyspark import SparkContext <span class="comment"># 驱动</span></span><br><span class="line">  from pyspark import SparkConf <span class="comment"># 基本配置，内存多少，任务名称</span></span><br><span class="line">  conf = SparkConf().setAppName(<span class="string">"miniProject"</span>).setMaster(<span class="string">"local[*]"</span>) <span class="comment"># 应用名称miniProject，路径在本地</span></span><br><span class="line">  sc = SparkContext.getOrCreate(conf) <span class="comment"># 对上面的应用进行初始化，如果有的话直接取过来，没有的话就创建</span></span><br><span class="line">  my_list = [1,2,3,4,5]</span><br><span class="line">  rdd = sc.parallelize(my_list) <span class="comment"># 并行化一个RDD数据，rdd是不可以直接看见，是一个对象，看不到内容</span></span><br><span class="line">  rdd.getNumPartitions() <span class="comment"># 存了多少份</span></span><br><span class="line">  rdd.glom().collect() <span class="comment"># 查看分区状况，collect是一个比较危险的命令，会把集群上的内容取到本地以列表返回，存在当前机器的内存中，可能会瞬间爆掉</span></span><br><span class="line"></span><br><span class="line">- 第二种通过本地文件进行读取</span><br><span class="line">  rdd = sc.textFile(<span class="string">"file://"</span>+os.getcwd()+<span class="string">'/nd.txt'</span>) <span class="comment"># 一定要将"file//"+绝对路径的这个文件，注意这种读取是以每一行为一个元素的读取，每个元素作为一个item</span></span><br><span class="line">  rdd = sc.wholeTextFiles(<span class="string">"file"</span>+cwd+<span class="string">"/names"</span>) <span class="comment"># 整个文件夹的内容(多个文件)进行读取, 对/names里面所有的文本进行读取，注意~这个时候读入的内容就是以元组内容进行组织的，(文件名,文件内容)</span></span><br></pre></td></tr></table></figure>
<h3 id="2-2-RDD的操作"><a href="#2-2-RDD的操作" class="headerlink" title="2.2 RDD的操作"></a>2.2 RDD的操作</h3><p><strong>Spark的transformations命令(非立即执行)</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">- map() <span class="comment"># 对RDD上的每个元素都进行同一操作，一进一出</span></span><br><span class="line">- flatMap() <span class="comment"># 对RDD中的item执行同一个操作之后得到一个list，然后以平铺的方式把list里所有的结果组成新的list，也就是一进多出</span></span><br><span class="line">- filter() <span class="comment"># 筛选出满足条件的item</span></span><br><span class="line">- distinct() <span class="comment"># 对RDD中item去重</span></span><br><span class="line">- sample() <span class="comment"># 从RDD中进行采样</span></span><br><span class="line">- sortBy(keyfunc=lambda (x,y):y, ascending=False <span class="comment"># 对RDD中的item进行排序</span></span><br><span class="line">- takeSample(3) <span class="comment"># 采样</span></span><br><span class="line">- map与flatmap之间的差别</span><br><span class="line">  strRDD = sc.parallelize([<span class="string">'hello world'</span>, <span class="string">'ni hao'</span>])</span><br><span class="line">  strRDD.map(lambda x: x.split(<span class="string">' '</span>)) <span class="comment"># 返回的是[['hello', 'world'], ['ni', 'hao']]</span></span><br><span class="line">  strRDD.flatMap(lambda x: x.split(<span class="string">' '</span>)) <span class="comment"># 返回的是[['hello', 'world', 'ni', 'hao']]</span></span><br><span class="line">- RDD数据的Transformation可以一个接一个的串联</span><br><span class="line">  def myfunc(x):</span><br><span class="line">    <span class="keyword">if</span> x%2==1:</span><br><span class="line">      <span class="built_in">return</span> 2*x</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="built_in">return</span> x</span><br><span class="line">  numberRDD = sc.parallelize(range(1,11)) <span class="comment"># 1-10</span></span><br><span class="line">  retRDD = (numberRDD.map(myfunc).filter(lambda x: x&gt;6).distinct())</span><br><span class="line">  retRDD.collect() <span class="comment"># 返回所有的结果</span></span><br><span class="line">- RDD之间的操作</span><br><span class="line">  rdd1.union(rdd2) <span class="comment"># 并集, 类似于两个list相加</span></span><br><span class="line">  rdd1.intersection(rdd2) <span class="comment"># 交集, 类似于python中的&amp;</span></span><br><span class="line">  rdd1.substract(rdd2) <span class="comment"># 差集,类似于python中的-</span></span><br><span class="line">  rdd1.cartesian(rdd2) <span class="comment"># 笛卡尔乘积,类似于排列组合的所有元素，python中的product</span></span><br></pre></td></tr></table></figure></p>
<p><strong>Spark的action命令(立即执行)</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- collect <span class="comment"># 危险！list形式返回</span></span><br><span class="line">- first() <span class="comment"># 返回第一个item</span></span><br><span class="line">- take(n) <span class="comment"># 返回n个item</span></span><br><span class="line">- count() <span class="comment"># 计算RDD中item的个数</span></span><br><span class="line">- top(n) <span class="comment"># 自然序排序取前n个</span></span><br><span class="line">- reduce(n) <span class="comment"># 做聚合</span></span><br></pre></td></tr></table></figure></p>
<p><strong>pairRDD操作</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">- 基本操作</span><br><span class="line">  reduceByKey() <span class="comment"># 对所有有着相同key的items执行reduce操作</span></span><br><span class="line">  groupByKey() <span class="comment"># 返回类似于(key, listOfValues)这种元组RDD，后面的value list是同一个key下面的</span></span><br><span class="line">  sortByKey() <span class="comment"># 按照key进行排序</span></span><br><span class="line">  countByKey() <span class="comment"># 按照key对item进行个数统计</span></span><br><span class="line">  countByValue() <span class="comment"># 按照value对item进行个数统计</span></span><br><span class="line"> collectAsMap() <span class="comment"># 与collect类似，返回的是k-v字典</span></span><br><span class="line">- 不同pairRDD之间进行关联</span><br><span class="line">  RDD1 = sc.parallelize([(<span class="string">'a'</span>,1), (<span class="string">'b'</span>,2), (<span class="string">'c'</span>,3)])</span><br><span class="line">  RDD1 = sc.parallelize([(<span class="string">'b'</span>,20), (<span class="string">'c'</span>,30), (<span class="string">'d'</span>,40)])</span><br><span class="line">  RDD1.join(RDD2).collect() <span class="comment"># 对两个pairRDD之间利用key进行连接</span></span><br><span class="line">  RDD1.leftOuterJoin(RDD2).collect() <span class="comment"># 对两个pairRDD之间利用key进行左连接，RDD1作为主导</span></span><br><span class="line">  RDD1.rightOuterJoin(RDD2).collect() <span class="comment"># 对两个pairRDD之间利用key进行左连接，RDD2作主导</span></span><br></pre></td></tr></table></figure></p>
<h3 id="2-3-初始化Spark-DataFrame的方法"><a href="#2-3-初始化Spark-DataFrame的方法" class="headerlink" title="2.3 初始化Spark DataFrame的方法"></a>2.3 初始化Spark DataFrame的方法</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">- 创建SparkSession类</span><br><span class="line">  from pyspark.sql import SparkSession</span><br><span class="line">  spark = SparkSession.builder.appName(<span class="string">'Python Spark SQL'</span>)\</span><br><span class="line">    .config(<span class="string">'spark.some.config.option'</span>, <span class="string">'some-value'</span>)\</span><br><span class="line">    .getOrCreate() <span class="comment"># 利用spark SQL构建一个入口</span></span><br><span class="line">- 关闭创建好的spark入口</span><br><span class="line">  spark.stop() <span class="comment"># 因为不能同时存在多个入口</span></span><br><span class="line">- 文件的读取</span><br><span class="line">  在SparkSession中可以从一个已存在的RDD或者hive表或者Spark数据源中创建一个DataFrame</span><br><span class="line">  df = spark.read.csv(<span class="string">"/path/to/your.csv"</span>) <span class="comment"># 读入csv文件</span></span><br><span class="line">- DataFrame操作</span><br><span class="line">  df.show() <span class="comment"># 展示数据</span></span><br><span class="line">  df.printSchema() <span class="comment"># 类似于Pandas里面的df.info()函数</span></span><br><span class="line">  df.describe([...]) <span class="comment"># 对list里面的各列进行统计</span></span><br><span class="line">  df.select([<span class="string">'name'</span>, <span class="string">'age'</span>]).show() <span class="comment"># 选两列</span></span><br><span class="line">  df.select(df[<span class="string">'name'</span>], df[<span class="string">'age'</span>]+1).show() <span class="comment"># 选取name这列同时age这列+1</span></span><br><span class="line">  df.filter(df[<span class="string">'age'</span>]&gt;21).show() <span class="comment"># 对数据进行filter</span></span><br><span class="line">  df.groupBy(<span class="string">'age'</span>).count().show() <span class="comment"># 对年龄分组同时统计人数，count类似于size</span></span><br><span class="line">  df.groupBy(<span class="string">'age'</span>).agg(...).show() <span class="comment"># 类似于pandas中的用法</span></span><br><span class="line">  df.select(<span class="string">'xx'</span>, df[<span class="string">'xx'</span>].cast(...).<span class="built_in">alias</span>(...)) <span class="comment"># 类型转换+重命名</span></span><br><span class="line">  df.withColumn(<span class="string">'xxx'</span>, ...) <span class="comment"># 对列进行处理同时产生新的列xxx</span></span><br><span class="line">  df.orderBy(<span class="string">'xxx'</span>, ascending=False) <span class="comment"># 对某列进行排序</span></span><br><span class="line">  df.filter(df[<span class="string">'value'</span>].isNull()).count() <span class="comment"># isNull空值处理</span></span><br><span class="line">  df.withColumn(<span class="string">'sex'</span>, lit(<span class="string">'man'</span>))) <span class="comment"># lit是用来产生独立的数据的</span></span><br><span class="line">  from pyspark.sql.functions import f <span class="comment"># 有很多内置的函数,包括udf自定义函数</span></span><br><span class="line">- 时间操作</span><br><span class="line">  df.withColumn(<span class="string">'day'</span>, dayofmonth(<span class="string">'time'</span>)) <span class="comment"># dayofmonth等函数的使用，这些函数也是内置在pyspark.sql.functions中的</span></span><br><span class="line">- 类型转换</span><br><span class="line">  RDD.toDF() <span class="comment"># RDD类型转换为spark DataFrame类型</span></span><br><span class="line">  scDF.toPandas() <span class="comment"># 转换spark DataFrame到pandas DataFrame</span></span><br><span class="line">  RDD = scDF.select(<span class="string">'col1'</span>, <span class="string">'col2'</span>).rdd.map(lambda r: (r[0], r[1])) <span class="comment"># spark DataFrame转RDD</span></span><br></pre></td></tr></table></figure>
<h3 id="2-4-初始化Spark-DataFrame的方法"><a href="#2-4-初始化Spark-DataFrame的方法" class="headerlink" title="2.4 初始化Spark DataFrame的方法"></a>2.4 初始化Spark DataFrame的方法</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意DataFrame不是一个表，所以如果想用SQL的方式进行表的查询的时候需要事先构建一个表</span></span><br><span class="line">df.createOrReplaceTemView(<span class="string">'sqltable'</span>)</span><br><span class="line">sqlDF = spark.sql(<span class="string">'SELECT * FROM sqltable'</span>) <span class="comment"># 使用SQL的方式对数据进行提取，spark是自己创建的，返回的结果还是DataFrame</span></span><br></pre></td></tr></table></figure>
<hr>




      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/03/15/ML-algrithom-usage/" rel="next" title="scikit-learn ML 算法实践">
                <i class="fa fa-chevron-left"></i> scikit-learn ML 算法实践
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/05/04/WaterMelonBook/" rel="prev" title="葫芦书读书笔记">
                葫芦书读书笔记 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/head.jpeg"
                alt="WenchaoXiu" />
            
              <p class="site-author-name" itemprop="name">WenchaoXiu</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#jupyter-notebook技巧"><span class="nav-number">1.</span> <span class="nav-text">jupyter notebook技巧</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-安装jupyter-notbook及其扩展"><span class="nav-number">1.1.</span> <span class="nav-text">1. 安装jupyter notbook及其扩展</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-jupyter使用设置"><span class="nav-number">1.2.</span> <span class="nav-text">2. jupyter使用设置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-pyhton2-python3-kernel共存"><span class="nav-number">1.3.</span> <span class="nav-text">3. pyhton2 python3 kernel共存</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-本地访问远端服务器"><span class="nav-number">1.4.</span> <span class="nav-text">4. 本地访问远端服务器</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Python包Pandas学习笔记"><span class="nav-number">2.</span> <span class="nav-text">Python包Pandas学习笔记</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-package的载入"><span class="nav-number">2.1.</span> <span class="nav-text">1 package的载入</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-数据读取-“-”暂作“或”使用"><span class="nav-number">2.2.</span> <span class="nav-text">2 数据读取(“/”暂作“或”使用)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-数据输出"><span class="nav-number">2.3.</span> <span class="nav-text">3 数据输出</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-创建DataFrame-Series对象"><span class="nav-number">2.4.</span> <span class="nav-text">4 创建DataFrame,Series对象</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-数据类型总结"><span class="nav-number">2.5.</span> <span class="nav-text">5 数据类型总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-查看数据"><span class="nav-number">2.6.</span> <span class="nav-text">6 查看数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-数据的截取"><span class="nav-number">2.7.</span> <span class="nav-text">7 数据的截取</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-数据清洗"><span class="nav-number">2.8.</span> <span class="nav-text">8 数据清洗</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-数据分组"><span class="nav-number">2.9.</span> <span class="nav-text">9 数据分组</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-数据合并"><span class="nav-number">2.10.</span> <span class="nav-text">10 数据合并</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11-时序数据操作"><span class="nav-number">2.11.</span> <span class="nav-text">11 时序数据操作</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#绘图命令"><span class="nav-number">3.</span> <span class="nav-text">绘图命令</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-pandas内置绘图"><span class="nav-number">3.1.</span> <span class="nav-text">1. pandas内置绘图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-matplotlib绘图的一些设置"><span class="nav-number">3.2.</span> <span class="nav-text">2. matplotlib绘图的一些设置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-seaborn绘图"><span class="nav-number">3.3.</span> <span class="nav-text">3. seaborn绘图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-一些图形实例"><span class="nav-number">3.4.</span> <span class="nav-text">4. 一些图形实例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-barplot"><span class="nav-number">3.4.1.</span> <span class="nav-text">4.1 barplot</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-scatter-plot"><span class="nav-number">3.4.2.</span> <span class="nav-text">4.2 scatter plot</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-pie-chart"><span class="nav-number">3.4.3.</span> <span class="nav-text">4.3 pie chart</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-分组scatter-plot"><span class="nav-number">3.4.4.</span> <span class="nav-text">4.4 分组scatter plot</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-5-histgram"><span class="nav-number">3.4.5.</span> <span class="nav-text">4.5 histgram</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-6-correlation-plot"><span class="nav-number">3.4.6.</span> <span class="nav-text">4.6 correlation plot</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-7-pairwise散点图"><span class="nav-number">3.4.7.</span> <span class="nav-text">4.7 pairwise散点图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-8-分类boxplot图"><span class="nav-number">3.4.8.</span> <span class="nav-text">4.8 分类boxplot图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-9-分类boxplot点图"><span class="nav-number">3.4.9.</span> <span class="nav-text">4.9 分类boxplot点图</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#大数据知识"><span class="nav-number">4.</span> <span class="nav-text">大数据知识</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-hadoop"><span class="nav-number">4.1.</span> <span class="nav-text">1. hadoop</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-pyspark-基于spark"><span class="nav-number">4.2.</span> <span class="nav-text">2. pyspark(基于spark)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-初始化RDD的方法"><span class="nav-number">4.2.1.</span> <span class="nav-text">2.1 初始化RDD的方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-RDD的操作"><span class="nav-number">4.2.2.</span> <span class="nav-text">2.2 RDD的操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-初始化Spark-DataFrame的方法"><span class="nav-number">4.2.3.</span> <span class="nav-text">2.3 初始化Spark DataFrame的方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-初始化Spark-DataFrame的方法"><span class="nav-number">4.2.4.</span> <span class="nav-text">2.4 初始化Spark DataFrame的方法</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-car"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WenchaoXiu</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
